{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline II: Facebook Prophet\n",
    "\n",
    "[[Prophet]](https://facebook.github.io/prophet/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from fbprophet import Prophet\n",
    "import yaml\n",
    "\n",
    "# Get the current project path (where you open the notebook)\n",
    "# and go up two levels to get the project path\n",
    "current_dir = Path.cwd()\n",
    "proj_path = current_dir.parent.parent\n",
    "\n",
    "# make the code in src available to import in this notebook\n",
    "import sys\n",
    "sys.path.append(os.path.join(proj_path,'src'))\n",
    "\n",
    "from metrics import mean_absolute_percentage_error, get_metrics\n",
    "from utils import make_dates, create_folder\n",
    "\n",
    "# Catalog contains all the paths related to datasets\n",
    "with open(os.path.join(proj_path, 'conf/catalog.yml'), \"r\") as f:\n",
    "    catalog = yaml.safe_load(f)['breakfast']\n",
    "    \n",
    "# Params contains all of the dataset creation parameters and model parameters\n",
    "with open(os.path.join(proj_path, 'conf/params.yml'), \"r\") as f:\n",
    "    params = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store 2277 upc 1600027527\n",
      "Processing range 2009-01-17 to 2011-01-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/13 17:26:11 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 2277 upc 3800031838\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 2277 upc 1111009477\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 2277 upc 7192100339\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 389 upc 1600027527\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 389 upc 3800031838\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 389 upc 1111009477\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 389 upc 7192100339\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 25229 upc 1600027527\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 25229 upc 3800031838\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 25229 upc 1111009477\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n",
      "Processing store 25229 upc 7192100339\n",
      "Processing range 2009-01-17 to 2011-01-29\n",
      "Processing range 2009-02-14 to 2011-02-26\n",
      "Processing range 2009-03-14 to 2011-03-26\n",
      "Processing range 2009-04-11 to 2011-04-23\n",
      "Processing range 2009-05-09 to 2011-05-21\n",
      "Processing range 2009-06-06 to 2011-06-18\n",
      "Processing range 2009-07-04 to 2011-07-16\n",
      "Processing range 2009-08-01 to 2011-08-13\n",
      "Processing range 2009-08-29 to 2011-09-10\n",
      "Processing range 2009-09-26 to 2011-10-08\n",
      "Processing range 2009-10-24 to 2011-11-05\n",
      "Processing range 2009-11-21 to 2011-12-03\n",
      "Processing range 2009-12-19 to 2011-12-31\n"
     ]
    }
   ],
   "source": [
    "# mlflow.set_tracking_uri(os.path.join(proj_path, 'logging'))\n",
    "# mlflow.set_experiment('experiment-prophet-delete')\n",
    "# Create mlflow tracking folder\n",
    "create_folder(os.path.join(proj_path, 'mlruns'))\n",
    "\n",
    "# Step 1: Read data\n",
    "merged_data = pd.read_csv(os.path.join(proj_path, \n",
    "                                       catalog['output_dir']['dir'], \n",
    "                                       catalog['output_dir']['merged']))\n",
    "merged_data['WEEK_END_DATE'] = pd.to_datetime(merged_data['WEEK_END_DATE'])\n",
    "merged_data['WEEK_END_DATE'] = merged_data['WEEK_END_DATE'] + timedelta(days=3)\n",
    "\n",
    "# Step2: Create date folds\n",
    "date_ranges = make_dates(params['breakfast']['experiment_dates'])\n",
    "\n",
    "# stores = params['breakfast']['dataset']['store_ids']\n",
    "# upcs = params['breakfast']['dataset']['upcs']\n",
    "# full_search = list(itertools.product(stores, upcs))\n",
    "\n",
    "\n",
    "# Step 3: Iterate over each store and upc pair.\n",
    "# For each pair, iterate over each period (fold), find the optimal\n",
    "# set of parameters for that fold and make the predictions\n",
    "# on the test period\n",
    "stores = list(params['breakfast']['dataset']['store_ids'].keys())\n",
    "upcs = list(params['breakfast']['dataset']['upc_ids'].keys())\n",
    "store_upc_pairs = list(itertools.product(stores, upcs))\n",
    "\n",
    "for store_id, upc_id in store_upc_pairs: \n",
    "    print(f'Processing store {store_id} upc {upc_id}')\n",
    "    #mlflow.set_tracking_uri(os.path.join(proj_path, 'mlruns'))\n",
    "    mlflow.set_tracking_uri(os.path.join('../../','mlruns'))\n",
    "    mlflow.set_experiment(f'{store_id}_{upc_id}')\n",
    "    \n",
    "    mlflow.runName = 'prophet_' + str(datetime.today())[:19]\n",
    "    # Iterate over each period, unpack tuple in each variable.\n",
    "    # in each of the period, we will find the best set of parameters,\n",
    "    # which will represent the time-series cross validation methodology\n",
    "    for _, train_start, train_end, valid_start, valid_end, test_start, test_end in date_ranges.itertuples():\n",
    "        print(f'Processing range {str(train_start.date())} to {str(test_end.date())}')\n",
    "\n",
    "        train_x = merged_data[(merged_data['WEEK_END_DATE']>=train_start) &\n",
    "                                  (merged_data['WEEK_END_DATE']<=valid_end) &\n",
    "                                  (merged_data['STORE_NUM']==store_id) &\n",
    "                                  (merged_data['UPC']==upc_id)][['WEEK_END_DATE','UNITS']]\n",
    "        # Doesn't need a validation period.\n",
    "        test_y = merged_data[(merged_data['WEEK_END_DATE']>=test_start) &\n",
    "                             (merged_data['WEEK_END_DATE']<=test_end) &\n",
    "                             (merged_data['STORE_NUM']==store_id) &\n",
    "                             (merged_data['UPC']==upc_id)][['WEEK_END_DATE','UNITS']]\n",
    "        # Prophet expects two columns, one with the label 'ds' for the dates and y for the values\n",
    "        train_x = train_x.rename(columns={'WEEK_END_DATE':'ds', 'UNITS':'y'})\n",
    "        test_y = test_y.rename(columns={'WEEK_END_DATE':'ds', 'UNITS':'y'})\n",
    "\n",
    "        # Iterate over the periods to make next-day forecasts\n",
    "        predictions = []\n",
    "        for i in range(test_y.shape[0]):\n",
    "\n",
    "            #Instantiate a new Prophet object that represents the model\n",
    "            model = Prophet(weekly_seasonality=True,\n",
    "                            yearly_seasonality=True,\n",
    "                            daily_seasonality=False)\n",
    "\n",
    "            #Call the built-in holiday collection for US to be included in the model\n",
    "            model.add_country_holidays(country_name='US')\n",
    "\n",
    "            # Fit the FB Prohpet Model\n",
    "            model.fit(pd.concat([train_x.iloc[i:], test_y.iloc[:i]]))\n",
    "            future = model.make_future_dataframe(periods=1, freq='7D')\n",
    "            fcst = model.predict(future)['yhat'].iloc[-1]\n",
    "            predictions.append(fcst)\n",
    "        \n",
    "        run_metrics = get_metrics(test_y['y'].values, predictions)\n",
    "        \n",
    "        # store predictions\n",
    "        fdir = os.path.join(proj_path, catalog['results']['dir'], f'{str(test_end.date())}')\n",
    "        fname = os.path.join(fdir, f'prophet_{store_id}_{upc_id}.csv')\n",
    "        create_folder(fdir)\n",
    "\n",
    "        test_y['preds'] = predictions\n",
    "        \n",
    "        test_y.to_csv(fname)\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_artifact(fname)\n",
    "            mlflow.log_param('model','prophet')\n",
    "            mlflow.log_metrics(run_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
