{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('CRITICAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import yaml\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, plotting, space_eval\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "# Get the current project path (where you open the notebook)\n",
    "# and go up two levels to get the project path\n",
    "current_dir = Path.cwd()\n",
    "proj_path = current_dir.parent.parent\n",
    "\n",
    "\n",
    "# make the code in src available to import in this notebook\n",
    "import sys\n",
    "sys.path.append(os.path.join(proj_path,'src'))\n",
    "\n",
    "from metrics import *\n",
    "from utils import *\n",
    "from scalers import *\n",
    "\n",
    "# Catalog contains all the paths related to datasets\n",
    "with open(os.path.join(proj_path, 'conf/catalog.yml'), \"r\") as f:\n",
    "    catalog = yaml.safe_load(f)['breakfast']\n",
    "    \n",
    "# Params contains all of the dataset creation parameters and model parameters\n",
    "with open(os.path.join(proj_path, 'conf/params.yml'), \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def set_model(n_layers:int=1, init_units:int=50, n_unit_strategy:str='stable', \n",
    "              dropout_p:float=0.1, num_timesteps: int=8, num_series: int=5, \n",
    "              lr:float=0.001, optimizer:str='adam', loss:str='mape'):\n",
    "    '''\n",
    "    # Gives flexibility\n",
    "    # Explore depth vs width of the RNN model\n",
    "    https://stackoverflow.com/questions/59072728/what-is-the-rule-to-know-how-many-lstm-cells-and-how-many-units-in-each-lstm-cel\n",
    "    # there are no rule of thumb, but here the decrease strategy will devide by i the number of units at each layer.\n",
    "    \n",
    "    Args\n",
    "        num_timesteps: the number of lags in the dataframes\n",
    "        num_series: the number of time series, specify 1 if univariate\n",
    "        n_unit_strategy: two options, stable and decrease. decrease will decrease the  \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    if n_unit_strategy == 'stable':\n",
    "        n_units = [init_units] * n_layers\n",
    "    if n_unit_strategy == 'decrease':\n",
    "        n_units = [max(int(init_units/i),1) for i in range(1,n_layers+1)]\n",
    "    \n",
    "    if n_layers > 1:\n",
    "        model.add(LSTM(n_units[0], return_sequences=True, input_shape=(num_timesteps, num_series)))\n",
    "        model.add(Dropout(dropout_p)) # Prevent overfitting\n",
    "        for i in range(1, n_layers):\n",
    "            model.add(LSTM(n_units[i], return_sequences=True))\n",
    "            model.add(Dropout(dropout_p)) \n",
    "        model.add(LSTM(n_units[-1]))\n",
    "        model.add(Dropout(dropout_p))\n",
    "    \n",
    "    else:\n",
    "        model.add(LSTM(n_units[0], return_sequences=False, input_shape=(num_timesteps, num_series)))\n",
    "        model.add(Dropout(dropout_p)) # Prevent overfitting\n",
    "\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    if optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 8, 50)             11200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8, 50)             20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8, 50)             20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,851\n",
      "Trainable params: 71,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_a = set_model(n_layers=3, n_unit_strategy='stable')\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, lag_units, list_features:list=['UNITS']):\n",
    "    \"\"\"\n",
    "    For every feature in the list of features, create lagged features\n",
    "    for a specified number of lagged units. The lenght must be the\n",
    "    same for all of the features. After creating the new features,\n",
    "    it filters on those and adds them to a list that will be \n",
    "    reshaped in the correct format.\n",
    "    \n",
    "    We go from a dataframe version:\n",
    "    \n",
    "    UNITS    | FEATURE_A | FEATURE_B |   ...\n",
    "    ---------|-----------|-----------|-------\n",
    "    \n",
    "    For every feature:\n",
    "        \n",
    "        Create the lagged features:\n",
    "\n",
    "        UNITS    | FEATURE_A | FEATURE_A-lag-1 |   ...\n",
    "        ---------|-----------|-----------------|-------  \n",
    "\n",
    "        Filter on each lagged feature and inverse columns:\n",
    "\n",
    "        FEATURE_A-lag-N | ... |  FEATURE_A-lag-1\n",
    "        ----------------|-----|------------------\n",
    "        \n",
    "        Convert to numpy as reshape by adding a dimension\n",
    "        (nrows, nlags) -> (nrows, nlags, 1)\n",
    "        \n",
    "    Concatenate each \"feature-specific matrix\" on the last dimension\n",
    "    \n",
    "    [(nrows, lagged-features-A, 1),\n",
    "     (nrows, lagged-features-B, 1),\n",
    "                  ...\n",
    "     (nrows, lagged-features-X, 1)]\n",
    "     \n",
    "     Results in: \n",
    "     \n",
    "     (nrows, nlags, N)\n",
    "    \n",
    "    \n",
    "    Note: We need to specify the column 'UNITS' in the list of features.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list\n",
    "    list_df = []\n",
    "    \n",
    "    for feature in list_features:\n",
    "        # create new features that will have the convention lag-<col_name>-<lagged unit>\n",
    "        make_lag_features(df, lag_units, col_name=feature, prefix_name=f'lag-{feature}',inplace=True)\n",
    "        # filter columns that were just created\n",
    "        # we are only appending lag something, so not actual features\n",
    "        dummy = df.filter(like=f'lag-{feature}')\n",
    "        # invert columns left to right (lag-1 ... lag-N) -> (lag-N ... lag-1)\n",
    "        dummy = dummy[dummy.columns[::-1]]\n",
    "        # add an extra dimension\n",
    "        dummy = dummy.values.reshape(dummy.shape[0], dummy.shape[1], 1)\n",
    "        # add the matrice to a list where it will get concatenated at the end\n",
    "        list_df.append(dummy)\n",
    "\n",
    "    # matrices in list_df must have shape (n_rows, n_cols, 1)\n",
    "    # so we can concatenate on the last axis\n",
    "    x_features = np.concatenate(list_df, axis=2)\n",
    "    y_feature = np.array(df['UNITS'].values)\n",
    "\n",
    "    return x_features, y_feature, df['WEEK_END_DATE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store 2277 upc 1600027527\n",
      "Processing range 2009-01-17 to 2011-01-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:09<00:00, 13.84s/it]\n",
      "2020/12/22 08:02:53 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-02-14 to 2011-02-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.55s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-03-14 to 2011-03-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:28<00:00, 17.65s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-04-11 to 2011-04-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:16<00:00, 27.22s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-05-09 to 2011-05-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:23<00:00, 28.78s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-06-06 to 2011-06-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:22<00:00, 28.49s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-07-04 to 2011-07-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:36<00:00, 31.22s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-01 to 2011-08-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.95s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-29 to 2011-09-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:15<00:00, 39.05s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-09-26 to 2011-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:04<00:00, 36.81s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-10-24 to 2011-11-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:34<00:00, 42.97s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-11-21 to 2011-12-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:47<00:00, 45.45s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-12-19 to 2011-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:36<00:00, 55.24s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store 2277 upc 3800031838\n",
      "Processing range 2009-01-17 to 2011-01-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:11<00:00, 62.26s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-02-14 to 2011-02-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:32<00:00, 54.41s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-03-14 to 2011-03-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:05<00:00, 61.10s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-04-11 to 2011-04-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [06:09<00:00, 73.88s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-05-09 to 2011-05-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [06:37<00:00, 79.43s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-06-06 to 2011-06-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [11:05<00:00, 133.10s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-07-04 to 2011-07-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [08:01<00:00, 96.32s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-01 to 2011-08-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:01<00:00, 156.36s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-29 to 2011-09-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [11:42<00:00, 140.43s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-09-26 to 2011-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [09:38<00:00, 115.79s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-10-24 to 2011-11-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [08:19<00:00, 100.00s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-11-21 to 2011-12-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [09:50<00:00, 118.11s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-12-19 to 2011-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [11:15<00:00, 135.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store 2277 upc 1111009477\n",
      "Processing range 2009-01-17 to 2011-01-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [11:58<00:00, 143.63s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-02-14 to 2011-02-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:25<00:00, 161.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-03-14 to 2011-03-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [11:56<00:00, 143.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-04-11 to 2011-04-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [12:29<00:00, 149.97s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-05-09 to 2011-05-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:13<00:00, 158.65s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-06-06 to 2011-06-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:53<00:00, 166.64s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-07-04 to 2011-07-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [16:34<00:00, 198.86s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-01 to 2011-08-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [14:57<00:00, 179.52s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-08-29 to 2011-09-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:57<00:00, 167.42s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-09-26 to 2011-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [17:37<00:00, 211.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing range 2009-10-24 to 2011-11-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\feras\\Anaconda3\\envs\\ForecastingRetailSales\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [11:42<13:12, 264.17s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Step 1: Read data\n",
    "merged_data = pd.read_csv(os.path.join(proj_path, catalog['output_dir']['dir'],catalog['output_dir']['merged']))\n",
    "merged_data['WEEK_END_DATE'] = pd.to_datetime(merged_data['WEEK_END_DATE'])\n",
    "merged_data['WEEK_END_DATE'] = merged_data['WEEK_END_DATE'] + timedelta(days=3)\n",
    "\n",
    "# Step 2: Create list of stores and upc pairs\n",
    "stores = list(params['breakfast']['dataset']['store_ids'].keys())\n",
    "upcs = list(params['breakfast']['dataset']['upc_ids'].keys())\n",
    "store_upc_pairs = list(itertools.product(stores, upcs))\n",
    "\n",
    "# Create date folds\n",
    "date_ranges = make_dates(params['breakfast']['experiment_dates'])\n",
    "\n",
    "for store_id, upc_id in store_upc_pairs: \n",
    "    print(f'Processing store {store_id} upc {upc_id}')\n",
    "    create_folder(os.path.join(proj_path, 'mlruns'))\n",
    "    #mlflow.set_tracking_uri(os.path.join(proj_path, 'mlruns'))\n",
    "    mlflow.set_tracking_uri(os.path.join('../../','mlruns'))\n",
    "    mlflow.set_experiment(f'{store_id}_{upc_id}')\n",
    "\n",
    "    # Iterate over each period, unpack tuple in each variable.\n",
    "    # in each of the period, we will find the best set of parameters,\n",
    "    # which will represent the time-series cross validation methodology\n",
    "    for _, train_start, train_end, valid_start, valid_end, test_start, test_end in date_ranges.itertuples():\n",
    "        print(f'Processing range {str(train_start.date())} to {str(test_end.date())}')\n",
    "\n",
    "        # This is the only different between experiment 2 and 3\n",
    "#         list_features = ['UNITS','VISITS','HHS','FEATURE','DISPLAY']\n",
    "        list_features = ['UNITS']\n",
    "\n",
    "        # Filter data here\n",
    "        # Prepare the dataset for one UPC and one store, currently no-scaling\n",
    "        filtered_data = merged_data[(merged_data['STORE_NUM']==store_id) &\n",
    "                                     (merged_data['UPC']==upc_id)][list_features+['WEEK_END_DATE']].copy()\n",
    "\n",
    "        \n",
    "        \n",
    "        # Initialize some of the parameters\n",
    "        ws = params['lstm']['window_size']\n",
    "        \n",
    "        # Prepare data, pass in all of the data, it will filter it\n",
    "        data, label, dates = prepare_data(filtered_data, ws, list_features=list_features)\n",
    "        \n",
    "        \n",
    "        # Because we are working with numpy now, it's easier to select the indexes\n",
    "        # Will need date indexes \n",
    "        date_series = pd.Series(dates)        \n",
    "        \n",
    "        train_series_idx = date_series[(date_series>=train_start) &\n",
    "                                       (date_series<=train_end)].index\n",
    "        valid_series_idx = date_series[(date_series>=valid_start) &\n",
    "                                       (date_series<=valid_end)].index\n",
    "        test_series_idx = date_series[(date_series>=test_start) &\n",
    "                                      (date_series<=test_end)].index\n",
    "        train_data = data[train_series_idx].copy()\n",
    "        train_label = label[train_series_idx].copy()\n",
    "        valid_data = data[valid_series_idx].copy()\n",
    "        valid_label = label[valid_series_idx].copy()\n",
    "        test_data = data[test_series_idx].copy()\n",
    "        test_label = label[test_series_idx].copy()\n",
    "        \n",
    "        # The scaling of 0 to 1 creates issue with the loss function, as the minimum will be 0 and maximum 1. \n",
    "        # a bad solution was to drop the row that has 0, but doesn't seem to help. \n",
    "        # another solution is to log the values\n",
    "        \n",
    "        scalers = {}\n",
    "        # The last two features are already bounded 0 to 1, we subtract 2 from the shape which represent 'FEATURE', 'DISPLAY'\n",
    "        # for feature_col in range(train_data.shape[-1]-2):\n",
    "        for feature_col in range(train_data.shape[-1]):\n",
    "            scalers[feature_col] = NormalizeScalerDf()\n",
    "            train_data[:,:,feature_col] = scalers[feature_col].fit_transform(train_data[:,:,feature_col])\n",
    "            valid_data[:,:,feature_col] = scalers[feature_col].transform(valid_data[:,:,feature_col])\n",
    "            test_data[:,:,feature_col] = scalers[feature_col].transform(test_data[:,:,feature_col])\n",
    "        scalers['label'] = NormalizeScalerDf()\n",
    "        train_label = scalers['label'].fit_transform(train_label)\n",
    "        valid_label = scalers['label'].transform(valid_label)\n",
    "        test_label = scalers['label'].transform(test_label)\n",
    "\n",
    "        # Replace NaN's with 0's which are caused by the lagged values. This was done after the scaling to avoid issues\n",
    "        train_data = np.nan_to_num(train_data)\n",
    "        valid_data = np.nan_to_num(valid_data)\n",
    "        test_data = np.nan_to_num(test_data)\n",
    "        \n",
    "        # Initialize some of the parameters\n",
    "        dp = params['lstm']['dropout']\n",
    "        units_strategy = params['lstm']['units_strategy']\n",
    "        optimizers = params['lstm']['optimizers']\n",
    "        losses = params['lstm']['loss']\n",
    "        num_series = train_data.shape[2]   \n",
    "        \n",
    "\n",
    "        # Step 3: Define a random search for these parameters, for hyperparameter tuning\n",
    "#         random_number_generator = np.random.RandomState(0) \n",
    "        param_grid = {'lr': uniform(loc=0.0001, scale=0.01),\n",
    "                      'init_units': randint(low=5, high= 100),\n",
    "                      'total_layers': randint(low=1, high=2)}\n",
    "        param_list = list(ParameterSampler(param_grid, n_iter=params['lstm']['search_iter'], random_state=3))\n",
    "        \n",
    "        \n",
    "        # Perform hyperparameter search\n",
    "        res = []\n",
    "        for param_dict in tqdm(param_list):\n",
    "            lr = param_dict['lr']\n",
    "            init_units = param_dict['init_units']\n",
    "            tot_lay = param_dict['total_layers']\n",
    "        \n",
    "            # Early Stopping will allow us to trigger when to stop training the model\n",
    "            # The stopping criteria will be when the validation loss doesn't decrease for \n",
    "            # two consecutive steps. This prevents us from overfitting the model. \n",
    "            earlyStop=EarlyStopping(monitor=\"val_loss\", verbose=0, mode='min', patience=2)\n",
    "            # Initialize the model and train\n",
    "            lstm_model = set_model(n_layers=tot_lay, init_units=init_units,\n",
    "                                   n_unit_strategy=units_strategy, dropout_p=dp,\n",
    "                                   num_timesteps=ws, num_series=num_series,\n",
    "                                   lr=lr, optimizer=optimizers, loss=losses)\n",
    "            history = lstm_model.fit(train_data, train_label, validation_data=(valid_data, valid_label), \n",
    "                                     epochs=1000, verbose=0, shuffle=False, batch_size=1, callbacks=[earlyStop])\n",
    "\n",
    "            # _ = lstm_model.predict(np.expand_dims(valid_data[0],axis=0))[0]\n",
    "            # There are many warnings when making predictions, thus I use a comprehension loop\n",
    "            # val_predictions = np.array([lstm_model.predict(np.expand_dims(dd,axis=0))[0] for dd in valid_data])\n",
    "            val_predictions = lstm_model.predict(valid_data)\n",
    "            \n",
    "            y_pred = scalers['label'].inverse_transform(val_predictions)\n",
    "            y_true = scalers['label'].inverse_transform(valid_label)\n",
    "\n",
    "            val_mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "            param_res = {'learning_rate':lr,\n",
    "                         'init_units':init_units,\n",
    "                         'n_layers':tot_lay,\n",
    "                         'val_mape':val_mape}\n",
    "\n",
    "            res.append(param_res)\n",
    "        \n",
    "        # Select the optimal hyper-parameters\n",
    "        best_params = pd.DataFrame(res).sort_values(by='val_mape', ascending=True).iloc[0]\n",
    "\n",
    "        lstm_model = set_model(n_layers=int(best_params['n_layers']),\n",
    "                               init_units=best_params['init_units'],\n",
    "                               n_unit_strategy=units_strategy,\n",
    "                               dropout_p=dp,\n",
    "                               num_timesteps=ws,\n",
    "                               num_series=num_series,\n",
    "                               lr=best_params['learning_rate'],\n",
    "                               optimizer=optimizers,\n",
    "                               loss=losses)\n",
    "\n",
    "        earlyStop=EarlyStopping(monitor=\"val_loss\", verbose=0, mode='min', patience=2)\n",
    "        history = lstm_model.fit(train_data, train_label, validation_data=(valid_data, valid_label),\n",
    "                                 epochs=100, verbose=0, shuffle=False, batch_size=1, callbacks=[earlyStop])\n",
    "\n",
    "        test_predictions = lstm_model.predict(test_data) \n",
    "        \n",
    "        y_pred = scalers['label'].inverse_transform(test_predictions)\n",
    "        y_true = scalers['label'].inverse_transform(test_label)\n",
    "        \n",
    "        test_metrics = get_metrics(y_true, y_pred)\n",
    "        \n",
    "        fdir = os.path.join(proj_path, catalog['results']['dir'], f'{str(test_end.date())}')\n",
    "        fname = os.path.join(fdir, f'lstm_exp1_{store_id}_{upc_id}.csv')\n",
    "        create_folder(fdir)\n",
    "\n",
    "        pd.DataFrame({'y_true': y_true,\n",
    "                      'y_pred': y_pred.flatten()}).to_csv(fname)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param('model','lstm')\n",
    "            mlflow.log_param('experiment','exp1')\n",
    "            mlflow.log_params(best_params)\n",
    "            mlflow.log_params(params['lstm'])\n",
    "            mlflow.log_metrics(test_metrics)\n",
    "            mlflow.log_artifact(fname)\n",
    "            mlflow.log_params({'g_cat_state':False,\n",
    "                               'g_cat_us':False,\n",
    "                               'g_cc_state':False,\n",
    "                               'g_cc_us':False})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
